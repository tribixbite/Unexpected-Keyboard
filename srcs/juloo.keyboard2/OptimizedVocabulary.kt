package juloo.keyboard2

import android.content.Context
import android.util.Log
import juloo.keyboard2.VocabularyCache
import juloo.keyboard2.Config // Assuming Config is in this package or imported
import java.io.BufferedReader
import java.io.IOException
import java.io.InputStream
import java.io.InputStreamReader
import java.util.*
import kotlin.collections.ArrayList
import kotlin.collections.HashMap
import kotlin.collections.HashSet
import kotlin.math.abs
import kotlin.math.min
import kotlin.math.max

/**
 * Optimized vocabulary filtering for neural swipe predictions
 * Ports web app swipe-vocabulary.js optimizations to Android
 *
 * Features:
 * - Common words fast-path for instant lookup
 * - Hierarchical vocabulary (common -> top5000 -> full)
 * - Combined confidence + frequency scoring
 * - Length-based filtering and word lookup
 */
class OptimizedVocabulary(private val context: Context) {

    private val TAG = "OptimizedVocabulary"

    // OPTIMIZATION: Single unified lookup structure (1 hash lookup instead of 3)
    private val vocabulary: MutableMap<String, WordInfo> = HashMap()

    // OPTIMIZATION Phase 2: Trie for constrained beam search (eliminates invalid paths)
    private val vocabularyTrie: VocabularyTrie = VocabularyTrie()

    // OPTIMIZATION Phase 2: Length-based buckets for fuzzy matching (reduces 50k iteration to ~2k)
    // Maps word length -> list of words with that length
    private val vocabularyByLength: MutableMap<Int, MutableList<String>> = HashMap()

    // Scoring parameters (tuned for 50k vocabulary)
    private val CONFIDENCE_WEIGHT = 0.6f
    private val FREQUENCY_WEIGHT = 0.4f
    private val COMMON_WORDS_BOOST = 1.3f  // Increased for 50k vocab
    private val TOP5000_BOOST = 1.0f
    private val RARE_WORDS_PENALTY = 0.75f // Strengthened for 50k vocab

    // Filtering thresholds
    private val minFrequencyByLength: MutableMap<Int, Float> = HashMap()

    // Disabled words filter (for Dictionary Manager integration)
    private var disabledWords: MutableSet<String> = HashSet()

    // Contraction handling (for apostrophe display)
    // Maps base word -> list of contraction variants (e.g., "well" -> ["we'll"])
    private var contractionPairings: MutableMap<String, MutableList<String>> = HashMap()
    // Maps apostrophe-free -> with apostrophe (e.g., "dont" -> "don't")
    private var nonPairedContractions: MutableMap<String, String> = HashMap()

    @Volatile
    private var isLoaded = false
    private var contractionsLoadedFromCache = false // v1.32.522: Track if contractions cached

    // OPTIMIZATION Phase 1 FIX: Cache ALL config settings to avoid SharedPreferences reads on every swipe
    // These are updated via updateConfig() when settings change
    private var _debugMode = false
    private var _confidenceWeight = CONFIDENCE_WEIGHT
    private var _frequencyWeight = FREQUENCY_WEIGHT
    private var _commonBoost = COMMON_WORDS_BOOST
    private var _top5000Boost = TOP5000_BOOST
    private var _rarePenalty = RARE_WORDS_PENALTY
    private var _swipeAutocorrectEnabled = true
    private var _maxLengthDiff = 2
    private var _prefixLength = 2
    private var _maxBeamCandidates = 3
    private var _minWordLength = 2
    private var _charMatchThreshold = 0.67f
    private var _useEditDistance = true
    private var _autocorrect_confidence_min_frequency: Int = 500 // Added for user-configured min frequency

    // OPTIMIZATION Phase 2: Cache parsed custom words to avoid JSON parsing on every swipe
    // Maps custom word -> frequency
    private val _cachedCustomWords: MutableMap<String, Int> = HashMap()
    private var _lastCustomWordsJson = "" // Track last parsed JSON to avoid redundant parsing

    /**
     * Get the vocabulary trie for constrained beam search.
     * Allows beam search to check if a prefix is valid before exploring it.
     *
     * @return The vocabulary trie, or null if not loaded
     */
    fun getVocabularyTrie(): VocabularyTrie? {
        return if (isLoaded) vocabularyTrie else null
    }

    /**
     * CRITICAL FIX: Update cached config settings to eliminate SharedPreferences reads in hot path
     * Call this from NeuralSwipeTypingEngine.updateConfig() when settings change
     */
    fun updateConfig(config: Config?) {
        if (config == null) return

        _debugMode = config.swipe_debug_detailed_logging

        // Use pre-calculated weights from Config.java
        _confidenceWeight = config.swipe_confidence_weight
        _frequencyWeight = config.swipe_frequency_weight

        // Boost/penalty values (use defaults if not set)
        _commonBoost = if (config.swipe_common_words_boost > 0) config.swipe_common_words_boost else COMMON_WORDS_BOOST
        _top5000Boost = if (config.swipe_top5000_boost > 0) config.swipe_top5000_boost else TOP5000_BOOST
        _rarePenalty = if (config.swipe_rare_words_penalty > 0) config.swipe_rare_words_penalty else RARE_WORDS_PENALTY

        // Autocorrect settings
        _swipeAutocorrectEnabled = config.swipe_beam_autocorrect_enabled
        _maxLengthDiff = config.autocorrect_max_length_diff
        _prefixLength = config.autocorrect_prefix_length
        _maxBeamCandidates = config.autocorrect_max_beam_candidates
        _minWordLength = config.autocorrect_min_word_length
        _charMatchThreshold = config.autocorrect_char_match_threshold
        _useEditDistance = "edit_distance" == config.swipe_fuzzy_match_mode
        _autocorrect_confidence_min_frequency = config.autocorrect_confidence_min_frequency // Cache this value


        // OPTIMIZATION Phase 2: Parse and cache custom words here instead of on every swipe
        try {
            val prefs = DirectBootAwarePreferences.get_shared_preferences(context)
            val customWordsJson = prefs.getString("custom_words", "{}")
            
            // Only parse if content changed
            if (customWordsJson != _lastCustomWordsJson) {
                _cachedCustomWords.clear()
                if (customWordsJson != "{}") {
                    val jsonObj = org.json.JSONObject(customWordsJson)
                    val keys = jsonObj.keys()
                    while (keys.hasNext()) {
                        val customWord = keys.next().toLowerCase(Locale.ROOT)
                        val customFreq = jsonObj.optInt(customWord, 1000)
                        _cachedCustomWords[customWord] = customFreq
                    }
                    Log.d(TAG, "Cached " + _cachedCustomWords.size + " custom words")
                }
                _lastCustomWordsJson = customWordsJson ?: "" // Handle null string
            }
        } catch (e: Exception) {
            Log.e(TAG, "Failed to parse custom words JSON", e)
            _cachedCustomWords.clear()
            _lastCustomWordsJson = "{}" // Reset on error
        }

        Log.d(TAG, "Config cached: confidenceWeight=" + _confidenceWeight + ", autocorrect=" + _swipeAutocorrectEnabled)
    }

    /**
     * Load vocabulary from assets with frequency data
     * Creates hierarchical structure for fast filtering
     */
    fun loadVocabulary(): Boolean {
        try {
            // OPTIMIZATION: Load vocabulary with fast-path sets built during loading
            val t0 = System.currentTimeMillis()
            loadWordFrequencies()
            val t1 = System.currentTimeMillis()
            Log.d(TAG, "‚è±Ô∏è loadWordFrequencies: " + (t1 - t0) + "ms")

            // Load custom words and user dictionary for beam search
            loadCustomAndUserWords()
            val t2 = System.currentTimeMillis()
            Log.d(TAG, "‚è±Ô∏è loadCustomAndUserWords: " + (t2 - t1) + "ms")

            // Load disabled words to filter from predictions
            loadDisabledWords()
            val t3 = System.currentTimeMillis()
            Log.d(TAG, "‚è±Ô∏è loadDisabledWords: " + (t3 - t2) + "ms")

            // OPTIMIZATION v1.32.522: Contractions also cached in binary format
            // Load contraction mappings for apostrophe display (only if not cached)
            if (!contractionsLoadedFromCache) {
                loadContractionMappings()
            }
            val t4 = System.currentTimeMillis()
            Log.d(TAG, "‚è±Ô∏è loadContractions: " + (t4 - t3) + "ms")

            // Initialize minimum frequency thresholds by word length
            initializeFrequencyThresholds()
            val t5 = System.currentTimeMillis()
            Log.d(TAG, "‚è±Ô∏è initFrequencyThresholds: " + (t5 - t4) + "ms")

            // OPTIMIZATION v1.32.524: Save binary cache AFTER all components loaded
            // Now includes vocabulary + contractions in V2 format
            if (!contractionsLoadedFromCache) {
                VocabularyCache.saveBinaryCache(
                    context,
                    vocabulary,
                    contractionPairings,
                    nonPairedContractions
                )
            }

            isLoaded = true

            return true
        } catch (e: Exception) {
            Log.e(TAG, "Failed to load vocabulary - NO FALLBACK ALLOWED", e)
            throw RuntimeException("Dictionary loading failed - fallback vocabulary deleted", e)
        }
    }

    /**
     * Filter and rank neural network predictions using vocabulary optimization
     * Implements fast-path lookup and combined scoring from web app
     */
    fun filterPredictions(rawPredictions: List<CandidateWord>, swipeStats: SwipeStats): List<FilteredPrediction> {
        Log.d(TAG, "DEBUG: Checking for 'asshole' in vocabulary. Is present: " + vocabulary.containsKey("asshole"))
        if (!isLoaded) {
            Log.w(TAG, "Vocabulary not loaded, returning raw predictions")
            return convertToFiltered(rawPredictions)
        }

        // CRITICAL FIX: Use CACHED config values instead of reading SharedPreferences on every swipe
        // These are updated via updateConfig() when settings change (called from NeuralSwipeTypingEngine)
        val debugMode = _debugMode
        val confidenceWeight = _confidenceWeight
        val frequencyWeight = _frequencyWeight
        val commonBoost = _commonBoost
        val top5000Boost = _top5000Boost
        val rarePenalty = _rarePenalty
        val swipeAutocorrectEnabled = _swipeAutocorrectEnabled
        val maxLengthDiff = _maxLengthDiff
        val prefixLength = _prefixLength
        val maxBeamCandidates = _maxBeamCandidates
        val minWordLength = _minWordLength
        val charMatchThreshold = _charMatchThreshold
        val useEditDistance = _useEditDistance

        if (debugMode && rawPredictions.isNotEmpty()) {
            val debug = StringBuilder("\nüîç VOCABULARY FILTERING DEBUG (top 10 beam search outputs):\n")
            debug.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
            val numToShow = min(10, rawPredictions.size)
            for (i in 0 until numToShow) {
                val candidate = rawPredictions[i]
                debug.append(String.format("#%d: \"%s\" (NN confidence: %.4f)\n", i + 1, candidate.word, candidate.confidence))
            }
            val debugMsg = debug.toString()
            Log.d(TAG, debugMsg)
            sendDebugLog(debugMsg)
        }

        // Build set of raw predictions for contraction filtering
        // Used to determine which contraction variant to create based on NN output
        // Example: NN predicts "whatd" ‚Üí only create "what'd" (not what'll, what's, etc.)
        val rawPredictionWords = HashSet<String>()
        for (candidate in rawPredictions) {
            rawPredictionWords.add(candidate.word.toLowerCase(Locale.ROOT).trim())
        }

        val validPredictions = ArrayList<FilteredPrediction>()
        val detailedLog = if (debugMode) StringBuilder("\nüìä DETAILED FILTERING PROCESS:\n") else null
        if (debugMode) detailedLog?.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")

        for (candidate in rawPredictions) {
            val word = candidate.word.toLowerCase(Locale.ROOT).trim()

            // Skip invalid word formats
            if (!word.matches("^[a-z]+$".toRegex())) {
                if (debugMode) detailedLog?.append(String.format("  ‚ùå \"%s\" - invalid format (not a-z only)\n", word))
                continue
            }

            // v1.32.513: Filter by starting letter accuracy (autocorrect_prefix_length setting)
            // If prefixLength > 0 and we have a firstChar, ensure prediction starts with correct prefix
            if (prefixLength > 0 && swipeStats.firstChar != '\u0000' && word.isNotEmpty()) {
                val expectedFirst = Character.toLowerCase(swipeStats.firstChar)
                val actualFirst = word[0]
                if (actualFirst != expectedFirst) {
                    if (debugMode) detailedLog?.append(String.format("  ‚ùå \"%s\" - wrong starting letter (expected '%c', got '%c')\n",
                        word, expectedFirst, actualFirst))
                    continue
                }
            }

            // FILTER OUT DISABLED WORDS (Dictionary Manager integration)
            if (disabledWords.contains(word)) {
                if (debugMode) detailedLog?.append(String.format("‚ùå \"%s\" - DISABLED by user\n", word))
                continue // Skip disabled words from beam search
            }

            // CRITICAL OPTIMIZATION: SINGLE hash lookup (was 3 lookups!)
            val info = vocabulary[word]
            if (info == null) {
                if (debugMode) detailedLog?.append(String.format("‚ùå \"%s\" - NOT IN VOCABULARY (not in main/custom/user dict)\n", word))
                continue // Word not in vocabulary
            }

            // OPTIMIZATION: Tier is embedded in WordInfo (no additional lookups!)
            // v1.33+: Use configurable boost values instead of hardcoded constants
            val boost: Float
            val source: String

            when (info.tier) {
                2.toByte() -> { // common (top 100)
                    boost = commonBoost  // v1.33+: configurable (default: 1.3)
                    source = "common"
                }
                1.toByte() -> { // top5000
                    boost = top5000Boost  // v1.33+: configurable (default: 1.0)
                    source = "top5000"
                }
                else -> { // regular (tier 0)
                    // Check frequency threshold for rare words
                    val hardcodedMinFreq = getMinFrequency(word.length)
                    
                    // Normalize the user's configured min frequency
                    val configMinFreqValue = _autocorrect_confidence_min_frequency
                    // Use a slightly different scale for Config frequency to avoid 0.0 for values like 100
                    val configNormalizedMinFreq = max(0.0f, configMinFreqValue.toFloat() / 10000.0f) // Scale 0-10000 -> 0-1.0
                    
                    // Take the maximum of the hardcoded baseline and the user's configured min frequency
                    // This ensures the word passes both (hardcoded baseline is still important for very rare words)
                    val effectiveMinFreq = max(hardcodedMinFreq, configNormalizedMinFreq)

                    if (info.frequency < effectiveMinFreq) {
                        if (debugMode) detailedLog?.append(String.format("‚ùå \"%s\" - BELOW FREQUENCY THRESHOLD (freq=%.4f < effective_min=%.4f (hardcoded=%.4f, config=%.4f) for length %d)\n",
                            word, info.frequency, effectiveMinFreq, hardcodedMinFreq, configNormalizedMinFreq, word.length))
                        continue // Below threshold
                    }
                    boost = rarePenalty
                    source = "vocabulary"
                }
            }

            // v1.33+: Pass configurable weights to scoring function
            val score = VocabularyUtils.calculateCombinedScore(candidate.confidence, info.frequency, boost, confidenceWeight, frequencyWeight)
            validPredictions.add(FilteredPrediction(word, score, candidate.confidence, info.frequency, source))

            // DEBUG: Show successful candidates with all scoring details
            if (debugMode) {
                detailedLog?.append(String.format("‚úÖ \"%s\" - KEPT (tier=%d, freq=%.4f, boost=%.2fx, NN=%.4f ‚Üí score=%.4f) [%s]\n",
                    word, info.tier, info.frequency, boost, candidate.confidence, score, source))
            }
        }

        if (debugMode && detailedLog != null) {
            detailedLog.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
            val detailedMsg = detailedLog.toString()
            Log.d(TAG, detailedMsg)
            sendDebugLog(detailedMsg)
        }

        // Sort by combined score (confidence + frequency)
        validPredictions.sortWith { a, b -> b.score.compareTo(a.score) }

        // AUTOCORRECT FOR SWIPE: Fuzzy match top beam candidates against custom words
        // This allows "parametrek" (custom) to match "parameters" (beam output)
        // v1.33+: OPTIMIZED - uses pre-loaded config from top of method (no redundant prefs reads)
        // v1.33.1: CRITICAL FIX - removed isEmpty check and match against raw beam outputs
        if (swipeAutocorrectEnabled && rawPredictions.isNotEmpty()) {
            try {
                // OPTIMIZATION Phase 2: Use cached custom words instead of reading SharedPreferences
                if (_cachedCustomWords.isNotEmpty()) {
                    // For each custom word, check if it fuzzy matches any top beam candidate
                    for ((customWord, customFreq) in _cachedCustomWords) {
                        // Check top N RAW beam candidates for fuzzy match (v1.33.1: CRITICAL FIX - was using validPredictions)
                        // This allows autocorrect to work even when ALL beam outputs are rejected by vocabulary filtering
                        for (i in 0 until min(maxBeamCandidates, rawPredictions.size)) {
                            val beamWord = rawPredictions[i].word

                            // v1.33+: Configurable fuzzy matching (uses pre-loaded params)
                            if (VocabularyUtils.fuzzyMatch(customWord, beamWord, charMatchThreshold, maxLengthDiff, prefixLength, minWordLength)) {
                                // Add custom word as autocorrect suggestion
                                val normalizedFreq = max(0.0f, (customFreq - 1).toFloat() / 9999.0f)
                                val tier = if (customFreq >= 8000) 2.toByte() else 1.toByte()
                                // v1.33+: Use configurable boost values
                                val boost = if (tier == 2.toByte()) commonBoost else top5000Boost

                                // Use RAW beam candidate's confidence for scoring (v1.33.1: CRITICAL FIX - was using validPredictions)
                                val confidence = rawPredictions[i].confidence

                                // v1.33.3: MULTIPLICATIVE SCORING - match quality dominates
                                // Custom words: base_score = NN_confidence (ignore frequency)
                                // final_score = base_score √ó (match_quality^3) √ó tier_boost
                                val matchQuality = VocabularyUtils.calculateMatchQuality(customWord, beamWord, useEditDistance)
                                val matchPower = matchQuality * matchQuality * matchQuality // Cubic
                                val baseScore = confidence  // Ignore frequency for custom words
                                val score = baseScore * matchPower * boost

                                validPredictions.add(FilteredPrediction(customWord, score, confidence, normalizedFreq, "autocorrect"))

                                if (debugMode) {
                                    val matchMsg = String.format("üîÑ AUTOCORRECT: \"%s\" (custom) matches \"%s\" (beam) ‚Üí added with score=%.4f\n",
                                        customWord, beamWord, score)
                                    Log.d(TAG, matchMsg)
                                    sendDebugLog(matchMsg)
                                }
                                break // Only match once per custom word
                            }
                        }
                    }

                    // Re-sort after adding autocorrect suggestions
                    validPredictions.sortWith { a, b -> b.score.compareTo(a.score) }
                }
            } catch (e: Exception) {
                Log.e(TAG, "Failed to apply autocorrect to beam candidates", e)
            }
        }

        // MAIN DICTIONARY FUZZY MATCHING: Match rejected beam outputs against dictionary words
        // v1.33.1: NEW - allows "proxity" (beam) to match "proximity" (dict)
        // Only run if autocorrect is enabled and we have few/no valid predictions
        if (swipeAutocorrectEnabled && validPredictions.size < 3 && rawPredictions.isNotEmpty()) {
            try {
                if (debugMode) {
                    val fuzzyMsg = String.format("\nüîç MAIN DICTIONARY FUZZY MATCHING (validPredictions=%d, trying to rescue rejected beam outputs):\n", validPredictions.size)
                    Log.d(TAG, fuzzyMsg)
                    sendDebugLog(fuzzyMsg)
                }

                // Check top beam candidates that were rejected by vocabulary filtering
                for (i in 0 until min(maxBeamCandidates, rawPredictions.size)) {
                    val beamWord = rawPredictions[i].word.toLowerCase(Locale.ROOT).trim()
                    val beamConfidence = rawPredictions[i].confidence

                    // Skip if this beam word already passed vocabulary filtering
                    if (vocabulary.containsKey(beamWord)) {
                        continue // Already in validPredictions
                    }

                    // OPTIMIZATION Phase 2: Use length-based buckets instead of iterating entire vocabulary
                    // This reduces iteration from 50k+ words to ~2k words (only similar lengths)
                    // v1.33.2: CRITICAL FIX - find BEST match (highest score), not FIRST match
                    val targetLength = beamWord.length
                    var bestMatch: String? = null
                    var bestScore = 0.0f
                    var bestFrequency = 0.0f
                    var bestSource: String? = null

                    // Iterate only through length buckets within maxLengthDiff range
                    val minLengthBucket = max(1, targetLength - maxLengthDiff)
                    val maxLengthBucket = targetLength + maxLengthDiff

                    for (len in minLengthBucket..maxLengthBucket) {
                        val bucket = vocabularyByLength[len]
                        if (bucket == null) continue // No words of this length

                        for (dictWord in bucket) {
                            val info = vocabulary[dictWord]
                            if (info == null) continue // Shouldn't happen

                            // Skip disabled words
                            if (disabledWords.contains(dictWord)) {
                                continue
                            }

                            // Try fuzzy matching
                            if (VocabularyUtils.fuzzyMatch(dictWord, beamWord, charMatchThreshold, maxLengthDiff, prefixLength, minWordLength)) {
                                // Determine tier boost for matched word
                                val boost: Float
                                val source: String
                                when (info.tier) {
                                    2.toByte() -> {
                                        boost = commonBoost
                                        source = "dict-fuzzy-common"
                                    }
                                    1.toByte() -> {
                                        boost = top5000Boost
                                        source = "dict-fuzzy-top5k"
                                    }
                                    else -> {
                                        boost = rarePenalty
                                        source = "dict-fuzzy"
                                    }
                                }

                                // v1.33.3: MULTIPLICATIVE SCORING - match quality dominates
                                // Dict fuzzy: Use configured weights but penalize rescue (0.8x) to prefer direct matches
                                val matchQuality = VocabularyUtils.calculateMatchQuality(dictWord, beamWord, useEditDistance)
                                val matchPower = matchQuality * matchQuality * matchQuality // Cubic
                                
                                var baseScore = (confidenceWeight * beamConfidence) + (frequencyWeight * info.frequency)
                                baseScore *= 0.8f // Penalty for not being a direct beam match
                                
                                val score = baseScore * matchPower * boost

                                // Keep track of best match (v1.33.2: don't break on first match!)
                                if (score > bestScore) {
                                    bestScore = score
                                    bestMatch = dictWord
                                    bestFrequency = info.frequency
                                    bestSource = source
                                }
                            }
                        } // End for dictWord in bucket
                    } // End for len in length range

                    // Add the best match found for this beam word (if any)
                    if (bestMatch != null) {
                        // RE-APPLY STARTING LETTER ACCURACY CHECK (CRITICAL FIX)
                        if (prefixLength > 0 && swipeStats.firstChar != '\u0000' && bestMatch.isNotEmpty()) {
                            val expectedFirst = Character.toLowerCase(swipeStats.firstChar)
                            val actualFirst = bestMatch[0]
                            if (actualFirst != expectedFirst) {
                                if (debugMode) {
                                    val matchMsg = String.format("‚ùå DICT FUZZY REJECTED: \"%s\" (dict) for \"%s\" (beam #%d, NN=%.4f) - wrong starting letter (expected '%c', got '%c')\n",
                                        bestMatch, beamWord, i + 1, beamConfidence, expectedFirst, actualFirst)
                                    Log.d(TAG, matchMsg)
                                    sendDebugLog(matchMsg)
                                }
                                bestMatch = null // Mark as invalid
                            }
                        }

                        if (bestMatch != null) { // Only add if still valid after re-check
                            validPredictions.add(FilteredPrediction(bestMatch, bestScore, beamConfidence, bestFrequency, bestSource!!))

                            if (debugMode) {
                                val matchMsg = String.format("üîÑ DICT FUZZY: \"%s\" (dict) matches \"%s\" (beam #%d, NN=%.4f) ‚Üí added with score=%.4f\n",
                                    bestMatch, beamWord, i + 1, beamConfidence, bestScore)
                                Log.d(TAG, matchMsg)
                                sendDebugLog(matchMsg)
                            }
                        }
                    }
                }

                // Re-sort after adding fuzzy matches
                if (validPredictions.isNotEmpty()) {
                    validPredictions.sortWith { a, b -> b.score.compareTo(a.score) }
                }
            } catch (e: Exception) {
                Log.e(TAG, "Failed to apply dictionary fuzzy matching", e)
            }
        }

        // CONTRACTION HANDLING: Add paired variants and modify non-paired contractions
        if (contractionPairings.isNotEmpty() || nonPairedContractions.isNotEmpty()) {
            try {
                val contractionVariants = ArrayList<FilteredPrediction>()

                // Process each prediction for contractions
                for (i in 0 until validPredictions.size) {
                    val pred = validPredictions[i]
                    val word = pred.word

                    // Check for paired contractions (base word exists: "well" -> "we'll")
                    // Filter by raw NN predictions to show only relevant contractions
                    // Example: NN predicted "whatd" ‚Üí only create "what'd" (not what'll, what's, etc.)
                    if (contractionPairings.containsKey(word)) {
                        val contractions = contractionPairings[word]!!

                        for (contraction in contractions) {
                            // Get apostrophe-free form of this contraction (what'd ‚Üí whatd)
                            val apostropheFree = contraction.replace("'", "").toLowerCase(Locale.ROOT)

                            // Only create this contraction variant if NN predicted the apostrophe-free form
                            // Example: only create "what'd" if raw predictions contain "whatd"
                            if (!rawPredictionWords.contains(apostropheFree)) {
                                // Skip this contraction - NN didn't predict this variant
                                if (debugMode) {
                                    val msg = String.format("üìù CONTRACTION FILTERED: \"%s\" ‚Üí skipped \"%s\" (NN didn't predict \"%s\")\n",
                                        word, contraction, apostropheFree)
                                    Log.d(TAG, msg)
                                    sendDebugLog(msg)
                                }
                                continue
                            }

                            // Add contraction variant with slightly lower score (0.95x)
                            // This ensures base word appears first, followed by contraction
                            // CRITICAL: word = contraction (for insertion), displayText = contraction (for UI)
                            // Both must be the contraction so tapping "we'll" inserts "we'll" not "well"
                            val variantScore = pred.score * 0.95f
                            contractionVariants.add(
                                FilteredPrediction(
                                    contraction,             // word for insertion (with apostrophe: "we'll")
                                    contraction,             // displayText for UI (with apostrophe: "we'll")
                                    variantScore,
                                    pred.confidence,
                                    pred.frequency,
                                    pred.source + "-contraction"
                                )
                            )

                            if (debugMode) {
                                val msg = String.format("üìù CONTRACTION PAIRING: \"%s\" ‚Üí added variant \"%s\" (NN predicted \"%s\")\n",
                                    word, contraction, apostropheFree)
                                Log.d(TAG, msg)
                                sendDebugLog(msg)
                            }
                        }
                    }

                    // Check for non-paired contractions (apostrophe-free form -> contraction)
                    // REPLACE the apostrophe-free form with the contraction
                    // Example: "cant" (not a real word) ‚Üí "can't" (the actual word)
                    // Note: Valid words like "well", "were", "id" are NOT in nonPairedContractions
                    if (nonPairedContractions.containsKey(word)) {
                        val contraction = nonPairedContractions[word]!!

                        // REPLACE the current prediction with the contraction (same score)
                        // This prevents invalid forms like "cant", "dont" from appearing
                        validPredictions[i] = FilteredPrediction(
                            contraction,             // word for insertion (with apostrophe: "can't")
                            contraction,             // displayText for UI (with apostrophe: "can't")
                            pred.score,              // Keep same score (not a variant, a replacement)
                            pred.confidence,
                            pred.frequency,
                            pred.source + "-contraction"
                        )

                        if (debugMode) {
                            val msg = String.format("üìù NON-PAIRED CONTRACTION: \"%s\" ‚Üí REPLACED with \"%s\" (score=%.4f)\n",
                                word, contraction, pred.score)
                            Log.d(TAG, msg)
                            sendDebugLog(msg)
                        }
                    }
                }

                // Add all contraction variants
                if (contractionVariants.isNotEmpty()) {
                    validPredictions.addAll(contractionVariants)
                    // Re-sort after adding variants
                    validPredictions.sortWith { a, b -> b.score.compareTo(a.score) }
                }
            } catch (e: Exception) {
                Log.e(TAG, "Failed to apply contraction modifications", e)
            }
        }

        // DEBUG: Show final ranking
        if (debugMode && validPredictions.isNotEmpty()) {
            val ranking = StringBuilder("\nüèÜ FINAL RANKING (after combining NN + frequency):\n")
            ranking.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
            val numToShow = min(10, validPredictions.size)
            for (i in 0 until numToShow) {
                val pred = validPredictions[i]
                val displayInfo = if (pred.word == pred.displayText) "" else " (display=\"" + pred.displayText + "\")"
                ranking.append(String.format("#%d: \"%s\"%s (score=%.4f, NN=%.4f, freq=%.4f) [%s]\n",
                    i + 1, pred.word, displayInfo, pred.score, pred.confidence, pred.frequency, pred.source))
            }
            ranking.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n")
            val rankingMsg = ranking.toString()
            Log.d(TAG, rankingMsg)
            sendDebugLog(rankingMsg)
        }

        // Apply swipe-specific filtering if needed
        return if (swipeStats.expectedLength > 0) {
            filterByExpectedLength(validPredictions, swipeStats.expectedLength)
        } else {
            validPredictions.subList(0, min(validPredictions.size, 10))
        }
    }

    /**
     * Load word frequencies from dictionary files
     * OPTIMIZATION: Single-lookup structure with tier embedded (1 lookup instead of 3)
     */
    private fun loadWordFrequencies() {
        // OPTIMIZATION v1.32.520: Try pre-processed binary cache first (100x faster!)
        // Binary format avoids JSON parsing and sorting overhead
        if (VocabularyCache.tryLoadBinaryCache(
                context,
                vocabulary,
                vocabularyTrie,
                vocabularyByLength,
                contractionPairings,
                nonPairedContractions
            )) {
            contractionsLoadedFromCache = true // Set the flag in OptimizedVocabulary
            return
        }

        // Fall back to JSON format with on-demand cache generation
        try {
            val inputStream = context.assets.open("dictionaries/en_enhanced.json")
            val reader = BufferedReader(InputStreamReader(inputStream))
            val jsonBuilder = StringBuilder()
            var line: String?
            while (reader.readLine().also { line = it } != null) {
                jsonBuilder.append(line)
            }
            reader.close()

            // Parse JSON object
            val jsonDict = org.json.JSONObject(jsonBuilder.toString())
            val keys = jsonDict.keys()
            var wordCount = 0

            // First pass: collect all words with frequencies to determine tiers
            val wordFreqList = ArrayList<MutableMap.MutableEntry<String, Int>>()
            while (keys.hasNext()) {
                val word = keys.next().toLowerCase(Locale.ROOT)
                if (word.matches("^[a-z]+$".toRegex())) {
                    val freq = jsonDict.getInt(word)
                    wordFreqList.add(AbstractMap.SimpleEntry(word, freq))
                }
            }

            // Sort by frequency descending (highest frequency first)
            // BOTTLENECK: O(n log n) sort of 50k items takes ~500ms on ARM devices
            wordFreqList.sortWith { a, b -> b.value.compareTo(a.value) }

            // Second pass: assign tiers based on sorted position
            for (i in 0 until min(wordFreqList.size, 150000)) {
                val entry = wordFreqList[i]
                val word = entry.key
                val rawFreq = entry.value

                // Normalize frequency from 128-255 range to 0-1 range
                val frequency = (rawFreq - 128).toFloat() / 127.0f

                // Determine tier based on sorted position
                // Tightened thresholds for 50k vocabulary (was top 5000, now top 3000)
                val tier: Byte
                if (i < 100) {
                    tier = 2 // common (top 100)
                } else if (i < 3000) {
                    tier = 1 // top3000 (6% of 50k vocab)
                } else {
                    tier = 0 // regular
                }

                vocabulary[word] = WordInfo(frequency, tier)
                vocabularyTrie.insert(word) // OPTIMIZATION Phase 2: Build trie during vocab load

                // OPTIMIZATION Phase 2: Add to length-based buckets for fuzzy matching
                val wordLength = word.length
                vocabularyByLength.getOrPut(wordLength) { ArrayList() }.add(word)

                wordCount++
            }

            Log.d(TAG, "Loaded JSON vocabulary: $wordCount words with frequency tiers")
            vocabularyTrie.logStats() // Log trie statistics

            // DO NOT save cache here - contractions haven't been loaded yet!
            // Cache will be saved after loadVocabulary() completes
        } catch (e: Exception) {
            Log.w(TAG, "JSON vocabulary not found, falling back to text format: " + e.message)

            // Fall back to text format (position-based frequency)
            try {
                val inputStream = context.assets.open("dictionaries/en.txt")
                val reader = BufferedReader(InputStreamReader(inputStream))

                var line: String?
                var wordCount = 0
                while (reader.readLine().also { line = it } != null) {
                    line = line!!.trim().toLowerCase(Locale.ROOT)
                    if (line!!.isNotEmpty() && line!!.matches("^[a-z]+$".toRegex())) {
                        // Position-based frequency
                        val frequency = 1.0f / (wordCount + 1.0f)

                        // Determine tier based on position
                        val tier: Byte
                        if (wordCount < 100) {
                            tier = 2 // common
                        } else if (wordCount < 5000) {
                            tier = 1 // top5000
                        } else {
                            tier = 0 // regular
                        }

                        vocabulary[line!!] = WordInfo(frequency, tier)
                        wordCount++

                        if (wordCount >= 150000) break
                    }
                }

                reader.close()
                Log.d(TAG, "Loaded text vocabulary: $wordCount words")
            } catch (e2: IOException) {
                Log.e(TAG, "Failed to load word frequencies", e2)
                throw RuntimeException("Could not load vocabulary", e2)
            }
        }
    }

    /**
     * Initialize minimum frequency thresholds by word length
     */
    private fun initializeFrequencyThresholds() {
        // Longer words can have lower frequency thresholds
        minFrequencyByLength[1] = 1e-4f
        minFrequencyByLength[2] = 1e-5f
        minFrequencyByLength[3] = 1e-6f
        minFrequencyByLength[4] = 1e-6f
        minFrequencyByLength[5] = 1e-7f
        minFrequencyByLength[6] = 1e-7f
        minFrequencyByLength[7] = 1e-8f
        minFrequencyByLength[8] = 1e-8f
        // 9+ words
        for (i in 9..20) {
            minFrequencyByLength[i] = 1e-9f
        }
    }

    private fun getMinFrequency(length: Int): Float {
        return minFrequencyByLength.getOrDefault(length, 1e-9f)
    }
    
    /**
     * Filter predictions by expected word length with tolerance
     */
    private fun filterByExpectedLength(predictions: List<FilteredPrediction>, expectedLength: Int): List<FilteredPrediction> {
        val tolerance = 2 // Allow ¬±2 characters
        
        val filtered = ArrayList<FilteredPrediction>()
        for (pred in predictions) {
            val lengthDiff = abs(pred.word.length - expectedLength)
            if (lengthDiff <= tolerance) {
                filtered.add(pred)
            }
        }
        
        return if (filtered.isNotEmpty()) filtered else predictions.subList(0, min(predictions.size, 5))
    }
    
    /**
     * Convert raw predictions to filtered format
     */
    private fun convertToFiltered(rawPredictions: List<CandidateWord>): List<FilteredPrediction> {
        val result = ArrayList<FilteredPrediction>()
        for (candidate in rawPredictions) {
            result.add(FilteredPrediction(candidate.word, candidate.confidence, 
                candidate.confidence, 0.0f, "raw"))
        }
        return result
    }
    
    /**
     * Check if vocabulary is loaded
     */
    fun isLoaded(): Boolean {
        return isLoaded
    }

    /**
     * Reload custom words, user dictionary, and disabled words without reloading main vocabulary
     * Called when Dictionary Manager makes changes
     * PERFORMANCE: Only reloads small dynamic sets, not the 10k main dictionary
     */
    fun reloadCustomAndDisabledWords() {
        if (!isLoaded) return

        // Clear old custom/user/disabled data
        disabledWords.clear()

        try {
            // Reload custom and user words (overwrites old entries)
            loadCustomAndUserWords()

            // Reload disabled words filter
            loadDisabledWords()

            Log.d(TAG, "Reloaded custom/user/disabled words (vocabulary size: " + vocabulary.size + ")")
        } catch (e: Exception) {
            Log.e(TAG, "Failed to reload custom/user/disabled words", e)
        }
    }
    
    /**
     * Get vocabulary statistics
     */
    fun getStats(): VocabularyStats {
        // Count by tier from unified structure
        var common = 0
        var top5k = 0
        for (info in vocabulary.values) {
            if (info.tier == 2.toByte()) common++
            else if (info.tier == 1.toByte()) top5k++
        }

        return VocabularyStats(
            vocabulary.size,
            common,
            top5k,
            isLoaded
        )
    }
    
    /**
     * Load custom words and Android user dictionary into beam search vocabulary
     * High frequency ensures they appear in predictions
     */
    private fun loadCustomAndUserWords() {
        if (context == null) return // Redundant check, context is non-null

        try {
            val prefs = DirectBootAwarePreferences.get_shared_preferences(context)

            // 1. Load custom words from SharedPreferences
            val customWordsJson = prefs.getString("custom_words", "{}")
            if (customWordsJson != "{}") {
                try {
                    val jsonObj = org.json.JSONObject(customWordsJson)
                    val keys = jsonObj.keys()
                    var customCount = 0
                    while (keys.hasNext()) {
                        val word = keys.next().toLowerCase(Locale.ROOT)
                        val frequency = jsonObj.optInt(word, 1000) // Raw frequency 1-10000

                        // Normalize frequency to 0.0-1.0 range (1.0 = most frequent)
                        // Aligns with main dictionary normalization
                        val normalizedFreq = max(0.0f, (frequency - 1).toFloat() / 9999.0f)

                        // Assign tier dynamically based on frequency
                        // Very high frequency (>=8000) = tier 2 (common boost)
                        // Otherwise = tier 1 (top5000 boost)
                        val tier = if (frequency >= 8000) 2.toByte() else 1.toByte()

                        vocabulary[word] = WordInfo(normalizedFreq, tier)
                        customCount++

                        // DEBUG: Log each custom word loaded
                        if (Log.isLoggable(TAG, Log.DEBUG)) {
                            val debugMsg = String.format("  Custom word loaded: \"%s\" (freq=%d ‚Üí normalized=%.4f, tier=%d)\n",
                                word, frequency, normalizedFreq, tier)
                            Log.d(TAG, debugMsg)
                            sendDebugLog(debugMsg)
                        }
                    }
                    val loadMsg = "Loaded $customCount custom words into beam search (frequency-based tiers)"
                    Log.d(TAG, loadMsg)
                    sendDebugLog(loadMsg + "\n")
                } catch (e: org.json.JSONException) {
                    Log.e(TAG, "Failed to parse custom words JSON", e)
                }
            }

            // 2. Load Android user dictionary
            try {
                val cursor = context.contentResolver.query(
                    android.provider.UserDictionary.Words.CONTENT_URI,
                    arrayOf(
                        android.provider.UserDictionary.Words.WORD,
                        android.provider.UserDictionary.Words.FREQUENCY
                    ),
                    null,
                    null,
                    null
                )

                cursor?.use {
                    val wordIndex = it.getColumnIndex(android.provider.UserDictionary.Words.WORD)
                    var userCount = 0

                    while (it.moveToNext()) {
                        val word = it.getString(wordIndex).toLowerCase(Locale.ROOT)
                        // User dictionary words should rank HIGH - user explicitly added them
                        // CRITICAL: Previous value (250 ‚Üí 0.025) ranked user words at position 48,736!
                        val frequency = 9000

                        // Normalize to 0-1 range (~0.90)
                        val normalizedFreq = max(0.0f, (frequency - 1).toFloat() / 9999.0f)

                        // Assign tier 2 (common boost) - user words are important
                        val tier: Byte = 2

                        vocabulary[word] = WordInfo(normalizedFreq, tier)
                        userCount++
                    }

                    Log.d(TAG, "Loaded $userCount user dictionary words into beam search")
                }
            } catch (e: Exception) {
                Log.e(TAG, "Failed to load user dictionary for beam search", e)
            }
        } catch (e: Exception) {
            Log.e(TAG, "Error loading custom/user words for beam search", e)
        }
    }

    /**
     * Load disabled words set for filtering beam search results
     */
    private fun loadDisabledWords() {
        if (context == null) { // Redundant check, context is non-null
            disabledWords = HashSet()
            return
        }

        try {
            val prefs = DirectBootAwarePreferences.get_shared_preferences(context)
            val disabledSet = prefs.getStringSet("disabled_words", HashSet())
            disabledWords = HashSet(disabledSet)
            Log.d(TAG, "Loaded " + disabledWords.size + " disabled words for beam search filtering")
        } catch (e: Exception) {
            Log.e(TAG, "Failed to load disabled words", e)
            disabledWords = HashSet()
        }
    }

    /**
     * Load contraction mappings for apostrophe display support
     * Loads both paired contractions (base word exists: "well" -> "we'll")
     * and non-paired contractions (base doesn't exist: "dont" -> "don't")
     */
    private fun loadContractionMappings() {
        if (context == null) { // Redundant check, context is non-null
            contractionPairings = HashMap()
            nonPairedContractions = HashMap()
            return
        }

        try {
            // Load paired contractions (base word -> list of contraction variants)
            try {
                val inputStream = context.assets.open("dictionaries/contraction_pairings.json")
                val reader = BufferedReader(InputStreamReader(inputStream))
                val jsonBuilder = StringBuilder()
                var line: String?
                while (reader.readLine().also { line = it } != null) {
                    jsonBuilder.append(line)
                }
                reader.close()

                // Parse JSON object: { "well": [{"contraction": "we'll", "frequency": 243}], ... }
                val jsonObj = org.json.JSONObject(jsonBuilder.toString())
                val keys = jsonObj.keys()
                var pairingCount = 0

                while (keys.hasNext()) {
                    val baseWord = keys.next().toLowerCase(Locale.ROOT)
                    val contractionArray = jsonObj.getJSONArray(baseWord)
                    val contractionList = ArrayList<String>()

                    for (i in 0 until contractionArray.length()) {
                        val contractionObj = contractionArray.getJSONObject(i)
                        val contraction = contractionObj.getString("contraction").toLowerCase(Locale.ROOT)
                        contractionList.add(contraction)
                    }

                    contractionPairings[baseWord] = contractionList
                    pairingCount += contractionList.size
                }

                Log.d(TAG, "Loaded $pairingCount paired contractions for " + contractionPairings.size + " base words")
            } catch (e: Exception) {
                Log.w(TAG, "Failed to load contraction pairings: " + e.message)
                contractionPairings = HashMap()
            }

            // Load non-paired contractions (without apostrophe -> with apostrophe)
            try {
                val inputStream = context.assets.open("dictionaries/contractions_non_paired.json")
                val reader = BufferedReader(InputStreamReader(inputStream))
                val jsonBuilder = StringBuilder()
                var line: String?
                while (reader.readLine().also { line = it } != null) {
                    jsonBuilder.append(line)
                }
                reader.close()

                // Parse JSON object: { "dont": "don't", "cant": "can't", ... }
                val jsonObj = org.json.JSONObject(jsonBuilder.toString())
                val keys = jsonObj.keys()

                while (keys.hasNext()) {
                    val withoutApostrophe = keys.next().toLowerCase(Locale.ROOT)
                    val withApostrophe = jsonObj.getString(withoutApostrophe).toLowerCase(Locale.ROOT)
                    nonPairedContractions[withoutApostrophe] = withApostrophe
                }

                Log.d(TAG, "Loaded " + nonPairedContractions.size + " non-paired contractions")
            } catch (e: Exception) {
                Log.w(TAG, "Failed to load non-paired contractions: " + e.message)
                nonPairedContractions = HashMap()
            }
        } catch (e: Exception) {
            Log.e(TAG, "Error loading contraction mappings", e)
            contractionPairings = HashMap()
            nonPairedContractions = HashMap()
        }
    }

    /**
     * Send debug log message to SwipeDebugActivity if available
     * Sends broadcast to be picked up by debug activity
     */
    private fun sendDebugLog(message: String) {
        if (context == null) return // Redundant check, context is non-null

        try {
            val intent = android.content.Intent("juloo.keyboard2.DEBUG_LOG")
            intent.`package` = context.packageName
            intent.putExtra("log_message", message)
            context.sendBroadcast(intent)
        } catch (e: Exception) {
            // Silently fail - debug activity might not be running
        }
    }
}
