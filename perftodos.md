# Performance and Optimization Todos for Data Loading

This document outlines identified performance bottlenecks in the dictionary, contraction, and frequency data loading processes, along with detailed recommendations for optimization.

## I. Summary of Bottlenecks

The primary performance issues stem from the way data files (dictionaries, contractions) are read, parsed, and processed during application startup or when a new language is selected. These operations, if performed on the main thread, can lead to significant UI freezes and a poor user experience.

1.  **Inefficient File Reading:** `WordPredictor.java` and `ContractionManager.java` read entire files into a `StringBuilder` before parsing. This causes large, intermediate memory allocations.
2.  **Slow JSON Parsing:** The use of `org.json.JSONObject` is known to be slow and memory-intensive for large datasets compared to streaming parsers or other libraries like `Gson` or `Moshi`.
3.  **Costly Index Generation:** The prefix index in `WordPredictor.java` is generated by iterating over the entire dictionary at load time. This is a CPU-intensive operation.
4.  **Synchronous I/O:** All file reading and parsing appears to be synchronous, which will block the calling thread.

---

## II. Optimization Plan

The following is a list of concrete tasks to address the identified bottlenecks.

### Todo 1: Implement a Binary Dictionary Format

**Problem:** Plain text formats (JSON, TXT) are slow to parse. Every time the dictionary is loaded, the app repeats the same work of converting text to an efficient in-memory representation.

**Solution:** Create a pre-processing script (e.g., a Python or Gradle task) that converts the source dictionary files (`.json` or `.txt`) into a custom binary format. This format would be a direct memory map of the final data structures.

**Action Items:**
*   **Define Binary Format:**
    *   **Header:** Contains metadata like version, language, number of words, and offsets to different data sections (e.g., word trie, frequency list).
    *   **Trie/DAFSA Data Block:** Store the dictionary words in a memory-efficient trie or a more compressed DAFSA (Directed Acyclic Finite State Automaton). This would replace the `_dictionary` `HashMap` and the `_prefixIndex` `HashMap<String, Set<String>>` entirely, as prefix lookups are inherent to this structure.
    *   **Frequency Data Block:** A simple array of integers, where the index corresponds to a word's ID in the trie/DAFSA.
*   **Create Conversion Script:**
    *   Write a script (`regenerate_binary_dictionary.py`?) that reads the `50k_words.json` (or other source files) and writes the binary dictionary file to the `assets` directory.
    *   This script should be integrated into the build process.
*   **Update Runtime Code:**
    *   Modify `WordPredictor.java` to load this new binary file.
    *   Instead of parsing text, it will read the binary data directly into a `ByteBuffer` (ideally a memory-mapped `MappedByteBuffer` for near-instant loading) and access the data structures with minimal processing.

**Benefits:**
*   **Drastically Faster Loading:** Reduces parsing time from O(N) in the size of the text to O(1) for memory mapping.
*   **Lower Memory Usage:** A well-designed binary format and a trie/DAFSA are significantly more memory-efficient than `HashMap`s.
*   **Eliminates Prefix Index Generation:** The trie/DAFSA structure inherently provides efficient prefix searches, removing the need for the costly `buildPrefixIndex()` step.

---

### Todo 2: Optimize Contraction and Bigram Loading

**Problem:** The contraction and bigram files, while smaller, still suffer from the same read-and-parse-JSON bottleneck.

**Solution:** Apply the same binary conversion strategy.

**Action Items:**
*   **Contractions:**
    *   Create a script to convert `contractions_non_paired.json` and `contraction_pairings.json` into a single binary file.
    *   This could use a simple format: a block for non-paired contractions (e.g., a serialized `HashMap`) and a block for the "known" contractions set.
    *   Update `ContractionManager.java` to load this binary file.
*   **Bigram/N-gram Data:**
    *   The current `BigramModel.java` uses hardcoded data, which is fast. However, the `loadFromFile` method hints at future expansion.
    *   If external files are to be used, they should also be converted to a compact binary format (e.g., integer-based IDs for words instead of strings) rather than being parsed from text at runtime.

---

### Todo 3: Ensure Asynchronous Loading

**Problem:** Even with a binary format, I/O operations should not block the main thread.

**Solution:** Ensure all dictionary and data loading is performed on a background thread.

**Action Items:**
*   **Wrap Loading in an `AsyncTask` or `ExecutorService`:**
    *   In `DictionaryManager.java`, when a new `WordPredictor` is created and `loadDictionary` is called, this entire operation should be moved off the main thread.
    *   A callback or `LiveData` can be used to notify the UI or other components once the dictionary is loaded and ready.
*   **Show Loading Indicator:** While a dictionary is loading in the background (e.g., during a language switch), the UI should reflect this state (e.g., disable the suggestion bar, show a toast or a subtle loading icon).

**Benefits:**
*   **Responsive UI:** Prevents the application from freezing during data loading.
*   **Improved User Experience:** The user is not blocked and receives feedback about the loading process.

---

### Todo 4: Streamline User Dictionary and Custom Word Handling

**Problem:** `loadCustomAndUserWords` queries the `UserDictionary` content provider, which can be slow, and parses a JSON string from `SharedPreferences`.

**Solution:** Cache this data more effectively and update it incrementally.

**Action Items:**
*   **Cache User Words:** Load the user dictionary once at startup and store it. Use a `ContentObserver` to listen for changes to `UserDictionary.Words.CONTENT_URI` and update the in-memory cache only when a change occurs, rather than re-querying every time.
*   **Incremental Updates to Prefix Index:** The current implementation of `reloadCustomAndUserWords` rebuilds the entire prefix index. Modify `buildPrefixIndex()` to support adding or removing words without a full rebuild. `WordPredictor.java` already has an `addToPrefixIndex` method, which is a good start, but a removal method would also be needed.
*   **Consider a separate, faster format for custom words** if the JSON in `SharedPreferences` becomes a bottleneck.

**Benefits:**
*   **Faster Updates:** Avoids costly re-loading and re-indexing for small changes.
*   **Reduced I/O:** Minimizes queries to the content provider.
