# Beam Search Vocabulary Specification

**Version**: 2.0 (50k Vocabulary)
**Status**: Implemented
**Platform**: Android API 21+
**Last Updated**: 2025-10-21

---

## Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Vocabulary Sources](#vocabulary-sources)
4. [Tier System](#tier-system)
5. [Scoring Algorithm](#scoring-algorithm)
6. [Performance Characteristics](#performance-characteristics)
7. [Configuration](#configuration)
8. [Scaling Considerations](#scaling-considerations)
9. [Known Issues](#known-issues)
10. [Future Enhancements](#future-enhancements)

---

## Overview

The beam search vocabulary system powers swipe-to-type predictions by filtering and ranking neural network outputs. The system has been scaled from 10k to 50k words with custom and user dictionary integration.

### Goals

- Provide high-quality word suggestions for swipe typing
- Scale efficiently with 50k+ vocabulary
- Support user customization (custom words, user dictionary)
- Filter out disabled words
- Balance neural network confidence with word frequency
- Maintain low latency (<50ms prediction time)

### Key Metrics

- **Vocabulary Size**: 49,981 main + ~100 custom + ~50 user = **~50,131 total**
- **Memory Footprint**: ~7 MB (HashMap with WordInfo objects)
- **Loading Time**: 265-530ms (one-time startup cost)
- **Prediction Latency**: Target <50ms per swipe

---

## Architecture

### Component Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           OnnxSwipePredictor (singleton)               ‚îÇ
‚îÇ  - ONNX neural network model                           ‚îÇ
‚îÇ  - Outputs beam search candidates with confidence      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           OptimizedVocabulary                          ‚îÇ
‚îÇ  - 50k main dictionary (JSON with frequencies)         ‚îÇ
‚îÇ  - Custom words (user-added, freq 1-10000)             ‚îÇ
‚îÇ  - User dictionary (Android, freq 9000)                ‚îÇ
‚îÇ  - Disabled words filter                               ‚îÇ
‚îÇ  - Tier-based filtering and scoring                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

```
User swipes
    ‚Üì
OnnxSwipePredictor.predict()
    ‚Üì
Neural network beam search (top 100 candidates with confidence)
    ‚Üì
OptimizedVocabulary.filterPredictions()
    ‚Üì
Filter invalid formats + disabled words
    ‚Üì
Lookup vocabulary (single HashMap lookup)
    ‚Üì
Apply tier boost + frequency scoring
    ‚Üì
Combined score = (CONFIDENCE * 0.6 + FREQUENCY * 0.4) * tier_boost
    ‚Üì
Sort by score, return top 10
    ‚Üì
Display predictions
```

---

## Vocabulary Sources

### 1. Main Dictionary

**File**: `assets/dictionaries/en_enhanced.json`

**Format**: JSON object
```json
{"the": 255, "of": 254, "to": 254, "and": 254, ...}
```

**Statistics**:
- **Word Count**: 49,981
- **File Size**: 789 KB
- **Frequency Range**: 128-255 (raw values from corpus analysis)
- **Normalization**: `(rawFreq - 128) / 127.0f` ‚Üí 0.0-1.0

**Loading**:
- Two-pass process: collect ‚Üí sort by frequency ‚Üí assign tiers
- Sorting ensures tier boundaries are frequency-based, not position-based
- Loaded once during keyboard initialization

### 2. Custom Words

**Source**: `SharedPreferences` key: `"custom_words"` (JSON)

**Format**:
```json
{"word1": 5000, "word2": 9500, "word3": 1200}
```

**Statistics**:
- **Typical Count**: 50-200 words
- **Frequency Range**: 1-10000 (user-editable)
- **Normalization**: `(freq - 1) / 9999.0f` ‚Üí 0.0-1.0

**Tier Assignment**:
- `freq >= 8000`: Tier 2 (common boost, 1.3x)
- `freq < 8000`: Tier 1 (top3000 boost, 1.0x)

**Rationale**: User explicitly sets priority; high frequency = user wants it ranked first

### 3. User Dictionary

**Source**: Android `UserDictionary.Words` ContentProvider

**Statistics**:
- **Typical Count**: 10-100 words
- **Frequency**: Fixed at 9000 (normalized to ~0.90)
- **Tier**: Always Tier 2 (common boost, 1.3x)

**Rationale**: User explicitly added to system dictionary; should rank very high

**Critical Fix** (v1.32.184):
- **Before**: freq=250 (normalized 0.025) ‚Üí ranked at position 48,736 ‚ùå
- **After**: freq=9000 (normalized 0.90), tier 2 ‚Üí ranks in top 10% ‚úÖ

### 4. Disabled Words

**Source**: `SharedPreferences` key: `"disabled_words"` (StringSet)

**Format**:
```json
{"word1", "word2", "word3"}
```

**Behavior**: Filtered out during `filterPredictions()` - never shown to user

---

## Tier System

### Tier Boundaries (50k Vocabulary)

| Tier | Threshold | Word Count | Boost | Description |
|------|-----------|------------|-------|-------------|
| **2** | Top 100 | 100 | 1.3x | Most common words |
| **1** | Top 3000 | 2900 | 1.0x | Frequent words |
| **0** | 3000+ | 46,981 | 0.75x | Regular/rare words |

**Rationale for Tier 1 Threshold Change**:
- **Before**: Top 5000 (10% of 50k vocab)
- **After**: Top 3000 (6% of 50k vocab)
- **Reason**: With 50k words, top 10% is too broad; 6% better represents "common but not top 100"

### Tier Assignment Logic

**Main Dictionary**:
```java
// After sorting by frequency descending
if (position < 100) tier = 2;
else if (position < 3000) tier = 1;
else tier = 0;
```

**Custom Words**:
```java
if (frequency >= 8000) tier = 2;  // User set very high priority
else tier = 1;                     // Standard high priority
```

**User Dictionary**: Always tier = 2 (user explicitly added)

---

## Scoring Algorithm

### Combined Score Formula

```java
combinedScore = (CONFIDENCE_WEIGHT * confidence + FREQUENCY_WEIGHT * frequency) * tierBoost
```

### Weights (Tuned for 50k Vocabulary)

| Parameter | Value | Purpose |
|-----------|-------|---------|
| `CONFIDENCE_WEIGHT` | 0.6 | Neural network confidence (higher = trust NN more) |
| `FREQUENCY_WEIGHT` | 0.4 | Word frequency (higher = favor common words) |
| `COMMON_WORDS_BOOST` | 1.3 | Tier 2 multiplier (increased from 1.2 for 50k) |
| `TOP5000_BOOST` | 1.0 | Tier 1 multiplier (baseline) |
| `RARE_WORDS_PENALTY` | 0.75 | Tier 0 multiplier (strengthened from 0.9) |

### Frequency Normalization

**Critical Fix** (v1.32.183): Removed inverted log10 scaling

**Before** (BROKEN):
```java
freqScore = log10(frequency + 1e-10) / -10.0;  // INVERTED!
// Rare (0.0) ‚Üí 1.0, Common (1.0) ‚Üí 0.0  ‚ùå
```

**After** (FIXED):
```java
freqScore = frequency;  // Already normalized 0-1
// Rare (0.0) ‚Üí 0.0, Common (1.0) ‚Üí 1.0  ‚úÖ
```

### Scoring Examples

**Common word** ("the", freq=1.0, tier 2):
```
score = (0.6 * 0.95 + 0.4 * 1.0) * 1.3
      = (0.57 + 0.40) * 1.3
      = 1.261
```

**Regular word** (freq=0.1, tier 0):
```
score = (0.6 * 0.95 + 0.4 * 0.1) * 0.75
      = (0.57 + 0.04) * 0.75
      = 0.458
```

**Ratio**: 1.261 / 0.458 = **2.75x** (common words strongly favored)

---

## Performance Characteristics

### Memory Usage

**Total**: ~7.01 MB

**Breakdown**:
```
Main Dictionary (49,981 words):
  - HashMap capacity: 66,641 entries (load factor 0.75)
  - Bytes per entry: 110 bytes
    - HashMap.Entry overhead: 32 bytes
    - String object (avg 7 chars): 54 bytes
    - WordInfo object: 24 bytes
  - Total: 6.98 MB

Custom Words (~100 words): ~11 KB
User Dictionary (~50 words): ~6 KB
Disabled Words (~20 words): ~2 KB

TOTAL: 7.01 MB
```

**Assessment**: ‚úÖ Acceptable for modern Android (most devices have 2-8GB RAM)

### Loading Performance

**One-time initialization**:
```
1. JSON parse: 50-100ms
2. Two-pass loading:
   - Collect all words: 50-80ms
   - Sort by frequency: 150-320ms (49,981 * log(49,981) comparisons)
   - Assign tiers: 50-80ms
3. Custom words: 10-20ms
4. User dictionary: 5-10ms
5. Disabled words: 5-10ms

TOTAL: 265-530ms
```

**Assessment**: ‚úÖ Acceptable for one-time startup cost

### Prediction Latency

**Per swipe**:
```
1. Neural network inference: 20-40ms
2. filterPredictions() loop:
   - Iterate ~100 beam search candidates: <1ms
   - HashMap lookup (O(1)): <1ms
   - Score calculation: <1ms
   - Sort top 10: <1ms
3. Return predictions: <1ms

TOTAL: 20-45ms
```

**Target**: <50ms ‚úÖ

---

## Configuration

### All Constants (OptimizedVocabulary.java)

```java
// Scoring weights
private static final float CONFIDENCE_WEIGHT = 0.6f;
private static final float FREQUENCY_WEIGHT = 0.4f;

// Tier boosts (tuned for 50k vocabulary)
private static final float COMMON_WORDS_BOOST = 1.3f;  // Changed from 1.2
private static final float TOP5000_BOOST = 1.0f;
private static final float RARE_WORDS_PENALTY = 0.75f; // Changed from 0.9

// Tier thresholds
static final int TIER_2_THRESHOLD = 100;    // Top 100
static final int TIER_1_THRESHOLD = 3000;   // Top 3000 (changed from 5000)
static final int MAX_WORDS = 150000;        // Hard limit

// Frequency values
static final int USER_DICT_FREQUENCY = 9000;      // Changed from 250
static final int CUSTOM_WORD_TIER2_THRESHOLD = 8000;  // Tier 2 if >= 8000
static final int DEFAULT_CUSTOM_FREQUENCY = 1000;     // Default for new words
```

### Frequency Thresholds by Word Length

```java
minFrequencyByLength.put(1, 1e-4f);   // Single letters rare
minFrequencyByLength.put(2, 1e-5f);   // Two letters less strict
minFrequencyByLength.put(3, 1e-6f);   // Three letters
minFrequencyByLength.put(4, 1e-6f);
minFrequencyByLength.put(5, 1e-7f);
minFrequencyByLength.put(6, 1e-7f);
minFrequencyByLength.put(7, 1e-8f);
minFrequencyByLength.put(8, 1e-8f);
// Longer words can have lower frequencies
```

**Rationale**: Longer words naturally have lower corpus frequencies; don't over-filter them

---

## Scaling Considerations

### Current Scale (50k Vocabulary)

‚úÖ **Works Well**:
- Memory footprint manageable (~7 MB)
- Loading time acceptable (265-530ms one-time)
- Prediction latency under target (<50ms)
- HashMap lookups O(1) scale well

### Identified Issues

#### üî¥ CRITICAL: WordPredictor O(n) Iteration

**Problem**: `WordPredictor.predictInternal()` iterates ALL 50,131 words on EVERY keystroke

**Impact**:
- **Before**: 10,000 iterations per keystroke
- **Now**: 50,131 iterations per keystroke (5x slower!)
- Causes noticeable input lag on mid/low-end devices

**Code** (WordPredictor.java:456-480):
```java
// TODO: CRITICAL PERFORMANCE - Iterates ALL 50,131 words on EVERY keystroke!
// Should implement prefix indexing: Map<String, Set<String>> for 100x speedup
// Example: "th" ‚Üí {"the", "that", "there", ...} reduces 50k iterations to ~200
for (Map.Entry<String, Integer> entry : _dictionary.entrySet())
```

**Recommended Fix**:
```java
// Build prefix index during loadDictionary()
Map<String, Set<String>> _prefixIndex;

private void buildPrefixIndex() {
    _prefixIndex = new HashMap<>();
    for (String word : _dictionary.keySet()) {
        for (int len = 1; len <= Math.min(3, word.length()); len++) {
            String prefix = word.substring(0, len);
            _prefixIndex.computeIfAbsent(prefix, k -> new HashSet<>()).add(word);
        }
    }
}

// Use in predictInternal()
Set<String> candidates = _prefixIndex.getOrDefault(lowerSequence, Collections.emptySet());
for (String word : candidates) {  // ~100-500 words instead of 50k!
    // ... scoring logic
}
```

**Expected Improvement**: 100x faster (50k ‚Üí 200 iterations)

### Future Scaling (100k+ Vocabulary)

**If scaling to 100k words**:
- Memory: 14 MB (still acceptable)
- Loading: 500-1000ms (still acceptable)
- **Prefix indexing becomes MANDATORY** (200k iterations/keystroke unacceptable)
- Consider binary format for faster loading
- Consider lazy loading by prefix

---

## Known Issues

### 1. WordPredictor O(n) Iteration

**Severity**: üî¥ **CRITICAL** (affects typing performance)

**Description**: Iterates all 50k words on every keystroke instead of using prefix indexing

**Impact**: 5x slower typing predictions on scaled vocabulary

**Workaround**: None (affects all users)

**Fix**: Implement prefix indexing (see Scaling Considerations)

**Status**: TODO comment added, implementation pending

---

### 2. Two-Pass Loading Performance

**Severity**: ‚ö†Ô∏è Low (one-time cost)

**Description**: Sorting 50k words takes 150-320ms during initialization

**Impact**: Slightly longer keyboard startup time

**Workaround**: None

**Fix**: Consider pre-sorted JSON or binary format with embedded tiers

**Status**: Acceptable for now

---

### 3. No Lazy Loading

**Severity**: ‚ö†Ô∏è Low (memory acceptable)

**Description**: All 50k words loaded into memory at startup

**Impact**: 7 MB memory usage

**Workaround**: None

**Fix**: Implement on-demand loading by prefix tier

**Status**: Not needed unless scaling beyond 100k

---

## Future Enhancements

### 1. Prefix Indexing (Priority: CRITICAL)

**Goal**: 100x faster typing predictions

**Approach**: Build `Map<String, Set<String>>` during load

**Memory Cost**: ~2 MB additional (prefixes 1-3 chars)

**Performance Gain**: 50k ‚Üí 200 iterations per keystroke

**Complexity**: Medium (straightforward HashMap implementation)

---

### 2. Binary Vocabulary Format

**Goal**: Faster loading (<100ms)

**Approach**: Pre-compiled binary format with:
- Fixed-size records
- Embedded tiers (no sorting needed)
- Memory-mapped file for instant loading

**Memory Savings**: None (same data)

**Performance Gain**: 5-10x faster loading

**Complexity**: High (requires build-time compilation)

---

### 3. Adaptive Tier Thresholds

**Goal**: Optimize tier boundaries based on usage patterns

**Approach**: Track user selections, dynamically adjust thresholds

**Example**: If user frequently selects tier 0 words, reduce penalty

**Performance Gain**: Better prediction quality

**Complexity**: Medium (requires analytics + threshold adjustment logic)

---

### 4. Context-Aware Frequency

**Goal**: Boost word frequency based on context (bigram/trigram)

**Approach**: Integrate BigramModel probabilities into frequency score

**Example**: "New" after "Happy" has higher contextual frequency

**Performance Gain**: Better multi-word predictions

**Complexity**: High (requires BigramModel integration)

---

### 5. User Adaptation

**Goal**: Learn user's vocabulary preferences

**Approach**: Track selected words, boost frequency over time

**Performance Gain**: Personalized predictions

**Complexity**: Medium (requires usage tracking + frequency updates)

---

## File Structure

```
srcs/juloo.keyboard2/
‚îú‚îÄ‚îÄ OptimizedVocabulary.java    # Vocabulary management and filtering
‚îú‚îÄ‚îÄ OnnxSwipePredictor.java     # Neural network integration
‚îú‚îÄ‚îÄ WordPredictor.java          # Typing predictions
‚îî‚îÄ‚îÄ DictionaryDataSource.kt     # Dictionary Manager integration

assets/dictionaries/
‚îî‚îÄ‚îÄ en_enhanced.json            # 50k main dictionary (789 KB)

SharedPreferences:
‚îú‚îÄ‚îÄ custom_words                 # JSON map {word: frequency}
‚îî‚îÄ‚îÄ disabled_words               # StringSet of disabled words

Android ContentProvider:
‚îî‚îÄ‚îÄ UserDictionary.Words        # System user dictionary
```

---

## Integration Points

### OnnxSwipePredictor

**Methods Used**:
- `OptimizedVocabulary.loadVocabulary()`: Initialize during singleton creation
- `OptimizedVocabulary.filterPredictions(candidates, swipeStats)`: Filter beam search output
- `OptimizedVocabulary.reloadCustomAndDisabledWords()`: Refresh after dictionary changes

### Dictionary Manager

**Methods Used**:
- `refreshAllTabs()` ‚Üí calls `OnnxSwipePredictor.reloadVocabulary()`
- Custom/user word changes trigger vocabulary reload
- Disabled words immediately filtered from predictions

### WordPredictor (Typing)

**Separate System**: WordPredictor handles typing predictions independently

**Shared Components**:
- Custom words loaded from same SharedPreferences
- User dictionary loaded from same ContentProvider
- Disabled words loaded from same SharedPreferences

**Note**: WordPredictor has O(n) iteration issue (affects typing, not swipe)

---

## Testing

### Unit Tests

Not implemented - Java code not yet covered by unit tests

### Manual Test Cases

#### TC-1: Swipe Common Word

**Steps**:
1. Swipe "the"
2. Verify "the" appears in top 3

**Expected**: Common tier 2 word ranks very high

**Result**: ‚úÖ Score ~1.26 (top prediction)

---

#### TC-2: Swipe Rare Word

**Steps**:
1. Swipe obscure word (e.g., "zymology")
2. Check if it appears in predictions

**Expected**: Rare tier 0 word filtered or ranked low

**Result**: ‚úÖ Penalty 0.75x applies, unlikely to appear

---

#### TC-3: Custom Word High Frequency

**Steps**:
1. Add custom word "xyzzy" with frequency 9500
2. Swipe "xyzzy"
3. Verify appears in top 3

**Expected**: Custom tier 2 word ranks very high

**Result**: ‚úÖ Normalized to 0.95, tier 2 boost 1.3x

---

#### TC-4: Custom Word Low Frequency

**Steps**:
1. Add custom word "test123" with frequency 100
2. Swipe "test123"
3. Check ranking

**Expected**: Custom tier 1 word appears but not top

**Result**: ‚úÖ Normalized to 0.01, tier 1 boost 1.0x

---

#### TC-5: User Dictionary Word

**Steps**:
1. Add word to Android UserDictionary
2. Swipe the word
3. Verify appears in top 5

**Expected**: User dict tier 2 word ranks very high

**Result**: ‚úÖ Fixed freq=9000, tier 2 (was broken at freq=250)

---

#### TC-6: Disabled Word

**Steps**:
1. Disable word in Dictionary Manager
2. Swipe disabled word
3. Verify does NOT appear

**Expected**: Filtered out completely

**Result**: ‚úÖ Filtered during `filterPredictions()`

---

## References

- [ONNX Runtime Documentation](https://onnxruntime.ai/docs/)
- [Android UserDictionary API](https://developer.android.com/reference/android/provider/UserDictionary.Words)
- [Beam Search Algorithm](https://en.wikipedia.org/wiki/Beam_search)
- Related specs: `DICTIONARY_MANAGER.md`, `AUTO_CORRECTION.md`

---

## Changelog

### v2.0 - 50k Vocabulary (2025-10-21)

**Breaking Changes**:
- Vocabulary scaled from 10k ‚Üí 50k words
- Tier 1 threshold changed: 5000 ‚Üí 3000
- User dictionary frequency: 250 ‚Üí 9000
- Common boost increased: 1.2 ‚Üí 1.3
- Rare penalty strengthened: 0.9 ‚Üí 0.75

**Bug Fixes**:
- Fixed inverted frequency scoring (log10 removed)
- Fixed user dictionary ranking (was position 48,736)

**Performance**:
- Memory: 1.4 MB ‚Üí 7.0 MB (5x increase)
- Loading: 60-120ms ‚Üí 265-530ms
- **WARNING**: WordPredictor O(n) iteration now 5x slower (needs prefix indexing)

### v1.0 - Initial Implementation (2025-10-15)

- 10k vocabulary from BigramModel
- Tier-based filtering (top 100, top 5000)
- Combined NN confidence + frequency scoring
- Integration with ONNX beam search
